# Projet 1 : DÃ©tection en temps rÃ©el avec webcam et image to text

### Ã‰noncÃ© :
DÃ©veloppez une application de dÃ©tection en temps rÃ©el qui utilise la webcam pour identifier des
objets dans l'environnement. L'application doit permettre :
- La visualisation du flux vidÃ©o de la webcam avec les objets dÃ©tectÃ©s en temps rÃ©el.
- La prise de photos Ã  partir du flux vidÃ©o.
- Le chargement d'images depuis le systÃ¨me de fichiers.
- Pour chaque image (prise par la webcam ou chargÃ©e), l'application doit :
* Identifier les objets prÃ©sents dans l'image.
* GÃ©nÃ©rer une description textuelle de l'image en utilisant un modÃ¨le "image to text".
* Afficher la description textuelle Ã  l'utilisateur.

### DÃ©tails :
- Utilisez OpenCV pour la capture vidÃ©o et le traitement d'images.
- Utilisez un modÃ¨le de dÃ©tection d'objets prÃ©-entraÃ®nÃ© de Hugging Face (ex:
facebook/detr-resnet-50). Explorez Yolo V11
- Utilisez un modÃ¨le "image to text" prÃ©-entraÃ®nÃ© de Hugging Face (ex:
nlpconnect/vit-gpt2-image-captioning).

#### Description dÃ©taillÃ©e :
L'application permettra Ã  l'utilisateur de visualiser le flux vidÃ©o de sa webcam avec les objets
dÃ©tectÃ©s en temps rÃ©el. Il pourra prendre des photos Ã  partir du flux vidÃ©o ou charger des
images depuis son ordinateur. Pour chaque image, l'application identifiera les objets
prÃ©sents et gÃ©nÃ©rera une description textuelle en utilisant un modÃ¨le "image to text"
prÃ©-entraÃ®nÃ©. La description sera affichÃ©e Ã  l'utilisateur dans l'interface Gradio.

### BibliothÃ¨ques :
- opencv-python
- transformers
- torch

### How to run the app : 
```
    python -m api_detection.main
    python -m api_description.main
    python -m api_intermediaire.main
    streamlit run app_streamlit/app.py
```

### Architecture Fichiers

``` 
    â”œâ”€â”€ ğŸ—‚ï¸ api_description
    â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
    â”‚   â”œâ”€â”€ ğŸ—‚ï¸ dev
    â”‚   â”‚       â””â”€â”€ ğŸ“„ dev_notebook.ipynb
    â”‚   â”œâ”€â”€ ğŸ—‚ï¸ tests
    â”‚   â”‚       â”œâ”€â”€ ğŸ“„ __init__.py
    â”‚   â”‚       â””â”€â”€ ğŸ“„ test_api_description.py
    â”‚   â”œâ”€â”€ ğŸ“„ requirements.txt
    â”‚   â”œâ”€â”€ ğŸ“„ main.py
    â”‚   â””â”€â”€ ğŸ“„ setup_model.py
    â”œâ”€â”€ ğŸ—‚ï¸ api_detection
    â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
    â”‚   â”œâ”€â”€ ğŸ—‚ï¸ tests
    â”‚   â”‚       â”œâ”€â”€ ğŸ“„ __init__.py
    â”‚   â”‚       â””â”€â”€ ğŸ“„ test_detection.py
    â”‚   â”œâ”€â”€ ğŸ“„ requirements.txt
    â”‚   â””â”€â”€ ğŸ“„ main.py
    â”œâ”€â”€ ğŸ—‚ï¸ api_intermediaire
    â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
    â”‚   â”œâ”€â”€ ğŸ—‚ï¸ dev
    â”‚   â”‚       â””â”€â”€ ğŸ“„ dev_notebook.ipynb
    â”‚   â”œâ”€â”€ ğŸ—‚ï¸ modules
    â”‚   â”‚       â””â”€â”€ ğŸ“„ db_tools.py
    â”‚   â”œâ”€â”€ ğŸ—‚ï¸ tests
    â”‚   â”‚       â”œâ”€â”€ ğŸ“„ __init__.py
    â”‚   â”‚       â””â”€â”€ ğŸ“„ test_intermediaire.py
    â”‚   â”œâ”€â”€ ğŸ“„ requirements.txt
    â”‚   â””â”€â”€ ğŸ“„ main.py
    â”œâ”€â”€ ğŸ—‚ï¸ app_streamlit
    â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
    â”‚   â”œâ”€â”€ ğŸ—‚ï¸ pages
    â”‚   â”‚       â”œâ”€â”€ ğŸ“„ 1_formulaire.py
    â”‚   â”‚       â””â”€â”€ ğŸ“„ 2_charger_images.py
    â”‚   â”œâ”€â”€ ğŸ—‚ï¸ modules
    â”‚   â”‚       â””â”€â”€ ğŸ“„ email_valide.py
    â”‚   â”œâ”€â”€ ğŸ—‚ï¸ tests
    â”‚   â”‚       â”œâ”€â”€ ğŸ“„ __init__.py
    â”‚   â”‚       â””â”€â”€ ğŸ“„ test_app_streamlit.py
    â”‚   â”œâ”€â”€ ğŸ“„ requirements.txt
    â”‚   â””â”€â”€ ğŸ“„ app.py
    â”œâ”€â”€ ğŸ—‚ï¸ database
    â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
    â”‚   â”œâ”€â”€ ğŸ—‚ï¸ data
    â”‚   â”‚       â”œâ”€â”€ ğŸ“„ db_init.py
    â”‚   â”‚       â””â”€â”€ ğŸ“„ models.py
    â”‚   â”œâ”€â”€ ğŸ—‚ï¸ dev
    â”‚   â”‚       â””â”€â”€ ğŸ“„ dev.py
    â”‚   â”œâ”€â”€ ğŸ—‚ï¸ modules
    â”‚   â”‚       â”œâ”€â”€ ğŸ“„ __init__.py
    â”‚   â”‚       â””â”€â”€ ğŸ“„ encryption_db.py
    â”‚   â”œâ”€â”€ ğŸ—‚ï¸ tests
    â”‚   â”‚       â”œâ”€â”€ ğŸ“„ __init__.py
    â”‚   â”‚       â””â”€â”€ ğŸ“„ test_orm.py
    â”‚   â”œâ”€â”€ ğŸ“„ requirements.txt
    â”‚   â”œâ”€â”€ ğŸ“„ main.py
    â”‚   â””â”€â”€ ğŸ“– users.db
    â”œâ”€â”€ ğŸ—‚ï¸ logs
    â”‚   â”œâ”€â”€ ğŸ“„ log_main.log
    â”‚   â””â”€â”€ ğŸ“„ log_test.log
    â”œâ”€â”€ ğŸ—‚ï¸ reference
    â”œâ”€â”€ ğŸ—‚ï¸ tests
    â”‚   â””â”€â”€ ğŸ“„ test_setup.py
    â”‚   â”œâ”€â”€ ğŸ—‚ï¸ assets
    â”‚       â””â”€â”€ ğŸ“„ react.svg
    â”œâ”€â”€ ğŸ“„ .gitignore
    â”œâ”€â”€ ğŸ“„ pytest.ini
    â”œâ”€â”€ ğŸ“„ README.md
    â”œâ”€â”€ ğŸ“„ requirements.in
    â””â”€â”€ ğŸ“„ requirements.txt
```

### Methode Merise
**MCD**
**MLD**
**MPD**

### RÃ©partition US:
- SPRINT 1 :
    **Hanna :** US 7 (5 points), US 6 (3 points)
    **Djanamali :** US 1 (2 points), US 2 (3 points), US 5 (3 points)
    **Cyril :** US 3 (5 points), US 4 (5 points)
- SPRINT 2 :
    **Hanna :** US 10, US 11, US 14 
    **Djanamali :** US 15 , US 16, US 8, US 9, US 12
    **Cyril :** US 17, US 18, US 19, US 20

### Liens Internes:
* [Excalidraw](https://excalidraw.com/#room=dc221f1a8d9507c1e77d,XtKv-aLhHVwFvLK4v--Q_Q) 
* [Story mapping sheets](https://docs.google.com/spreadsheets/d/1aZ3k_PSkeQrGVGQ7HDYPhYgNXTsV9dMSDWWDFndWSDg/edit?gid=0#gid=0)
* [Story mapping Miro](https://miro.com/app/board/uXjVGbXlrEQ=/)
* [Logiciel Gestion Taiga](https://tree.taiga.io/project/cyril07-projet-1-detection-en-temps-reel-avec-webcam-et-image-to-text/backlog)
* [docs](https://docs.google.com/document/d/1z-2EQtrSnGrUCZtEnxD7ydTiCBjTCLG9PlurV5bL-g8/edit?tab=t.0)

### Sources:

* [OpenCV Capture Video from Camera](https://docs.opencv.org/4.x/dd/d43/tutorial_py_video_display.html)
* [modÃ¨le de dÃ©tection d'objets](https://huggingface.co/facebook/detr-resnet-50)
* [modÃ¨le de dÃ©tection d'objets YOLO](https://docs.ultralytics.com/fr/modes/predict/#why-use-ultralytics-yolo-for-inference)
* [liste modeles open cv](https://huggingface.co/opencv)
* [modÃ¨le "image to text"](https://huggingface.co/nlpconnect/vit-gpt2-image-captioning)
* [modele â€œimage to text2â€](https://huggingface.co/Salesforce/blip-image-captioning-large)

[![Build Status](https://github.com/PSEUDO/DEPOT/actions/workflows/build_tests.yml/badge.svg)](https://github.com/PSEUDO/DEPOT/actions)